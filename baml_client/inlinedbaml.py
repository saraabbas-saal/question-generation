# ----------------------------------------------------------------------------
#
#  Welcome to Baml! To use this generated code, please run the following:
#
#  $ pip install baml
#
# ----------------------------------------------------------------------------

# This file was generated by BAML: please do not edit it. Instead, edit the
# BAML files and re-generate this code using: baml-cli generate
# baml-cli is available with the baml package.

_file_map = {

    "abbreviation.baml": "// Military abbreviation correction data models\ntemplate_string ChainOfThought(action: string?) #\"\n    Before you answer, please explain your reasoning step-by-step of choosing the abbreviation.\n    {% if action %}{{ action }}{% endif %}\n    \n\"#\n\nclass TeachingMaterial {\n  text_en string\n  text_ar string\n  context string?\n}\n\nclass ClosestAbbreviation {\n  original string\n  closest string\n  confidence string\n  decoding map<string,string> @description(#\"\n    What each letter in the Abbreviation stands for\n  \"#)\n  reasoning string\n}\n\n\n// Function to correct altered military abbreviations in teaching materials\nfunction DecodeMilitaryAbbreviations(material: TeachingMaterial) -> ClosestAbbreviation {\n  client \"VLLM2\"\n  prompt #\"\n    You are an expert in military terminology and abbreviations.\n\n    \n    For each abbreviation found:\n    1. map the abbreviation to the closest common militay term \n    2. Determine the correct military abbreviation decoding\n    3. Assess confidence level (High/Medium/Low)\n    4. Provide the full meaning\n    5. Explain your reasoning for the correction\n\n    Text to analyze:\n      {{ material.text_en }}\n      {{ material.text_ar }}\n    \n    There is also extra context that can be of help: {{material.context}}\n\n    {{ ctx.output_format }}\n     {{ ChainOfThought(\"Determine the closest military abbreviation\") }}\n  \"#\n}\n\n// Test basic VUCA alteration\ntest test_vuca_correction {\n  functions [DecodeMilitaryAbbreviations]\n  args {\n    material {\n      text_en \"Remember the VUCAR framework when analyzing the battlefield environment.\"\n      text_ar \"يشرح عناصر إطار عمل نموذج تدريب وتعليم القيادة في معهد القوات الجوية والدفاع الجوي\" \n      context \" VUCAR is a military term that is used in AFADI that maps to VUCA but the R stands for Resilience\"\n    }\n  }\n}\n\n// Test multiple abbreviations\ntest test_multiple_corrections {\n  functions [DecodeMilitaryAbbreviations]\n  args {\n    material {\n      text_en \"State the meaning of \\\"PEA\\\" and \\\"NEA\\\".\"\n      text_ar \" يبين معنى عامل الجذب العاطفي الإيجابي وعامل الجذب العاطفي السلبي \"\n    }\n  }\n}\n\n\n// Test tactical abbreviations\ntest test_tactical_abbreviations {\n  functions [DecodeMilitaryAbbreviations]\n  args {\n    material {\n      text_en \"Complete your METT-CT analysis before developing the OPRD. Don't forget PACEE communications plan.\"\n      text_ar \"أكمل تحليل METT-CT قبل تطوير OPRD. لا تنس خطة الاتصالات PACEE\"\n      context \"\"\n    }\n  }\n}\n\n// Test intelligence abbreviations\ntest test_intelligence_abbreviations {\n  functions [DecodeMilitaryAbbreviations]\n  args {\n    material {\n      text_en \"Use PMSEII analysis for the region and apply CARVR methodology to identify targets.\"\n      text_ar \"استخدم تحليل PMSEII للمنطقة وطبق منهجية CARVR لتحديد الأهداف\"\n      context \"\"\n    }\n  }\n}\n\n// Test mixed alterations\ntest test_complex_alterations {\n  functions [DecodeMilitaryAbbreviations]\n  args {\n    material {\n      text_en \"During planning phase: 1) Conduct SWTO analysis 2) Use OAKOCK terrain assessment 3) Apply VUAC principles 4) Submit SITUPREP hourly\"\n      text_ar \"خلال مرحلة التخطيط: 1) أجري تحليل SWTO 2) استخدم تقييم التضاريس OAKOCK 3) طبق مبادئ VUAC 4) قدم SITUPREP كل ساعة\"\n      context \"\"\n    }\n  }\n}\n\n// Test minimal alterations\ntest test_minimal_changes {\n  functions [DecodeMilitaryAbbreviations]\n  args {\n    material {\n      text_en \"Leadership must understand VUCA volatility and use MDNP process for decisions. Brief includes SMEACC format.\"\n      text_ar \"يجب على القيادة فهم تقلبات VUCA واستخدام عملية MDNP للقرارات. يشمل الإحاطة تنسيق SMEACC\"\n      context \"\"\n    }\n  }\n}\n\n// Test document with correct abbreviations\ntest test_no_corrections_needed {\n  functions [DecodeMilitaryAbbreviations]\n  args {\n    material {\n      text_en \"Apply VUCA analysis using OODA loop. Standard METT-TC factors remain critical.\"\n      text_ar \"طبق تحليل VUCA باستخدام حلقة OODA. تبقى عوامل METT-TC المعيارية بالغة الأهمية\"\n      context \"\"\n    }\n  }\n}",
    "clients.baml": "// Learn more about clients at https://docs.boundaryml.com/docs/snippets/clients/overview\nclient<llm> VLLM {\n  provider \"openai-generic\"\n  options {\n    base_url env.MODEL_HOST\n    api_key env.MODEL_API_KEY\n    model env.MODEL_NAME\n    default_role \"user\" // Required for using VLLM\n    temperature 0.7\n    top_p 0.8\n    top_k 20\n    repetition_penalty 1.05\n\n  }\n}\n\nclient<llm> VLLM2 {\n  provider \"openai-generic\"\n  options {\n    base_url env.MODEL_HOST\n    api_key env.MODEL_API_KEY\n    model env.MODEL_NAME\n    default_role \"user\" // Required for using VLLM\n    temperature 0\n    top_p 0.8\n    top_k 20\n    repetition_penalty 1.05\n    seed 123\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/retry\nretry_policy Constant {\n  max_retries 3\n  // Strategy is optional\n  strategy {\n    type constant_delay\n    delay_ms 200\n  }\n}\n\nretry_policy Exponential {\n  max_retries 2\n  // Strategy is optional\n  strategy {\n    type exponential_backoff\n    delay_ms 300\n    multiplier 1.5\n    max_delay_ms 10000\n  }\n}",
    "generators.baml": "// This helps use auto generate libraries you can use in the language of\n// your choice. You can have multiple generators if you use multiple languages.\n// Just ensure that the output_dir is different for each generator.\ngenerator target {\n    // Valid values: \"python/pydantic\", \"typescript\", \"ruby/sorbet\", \"rest/openapi\"\n    output_type \"python/pydantic\"\n\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir \"../\"\n\n    // The version of the BAML package you have installed (e.g. same version as your baml-py or @boundaryml/baml).\n    // The BAML VSCode extension version should also match this version.\n    version \"0.90.2\"\n\n    // Valid values: \"sync\", \"async\"\n    // This controls what `b.FunctionName()` will be (sync or async).\n    default_client_mode async\n}\n",
    "question_generation.baml": "// Question generation data models\nclass QuestionOption {\n  key string\n  value string\n}\n\nclass GeneratedQuestion {\n  question_number int\n  question string\n  options QuestionOption[]\n  answer string[]\n  explanation string?  // Changed from model_answer to explanation\n}\n\nclass QuestionGenerationResult {\n  \n  questions GeneratedQuestion[]\n  teaching_point string\n  question_type string\n  language string\n  bloom_level string\n}\n\n// Function to generate questions based on teaching points\nfunction GenerateQuestions(\n  teaching_point_en: string,\n  teaching_point_ar: string,\n  context: string?,\n  question_type: string,\n  number_of_distractors: int?,\n  number_of_correct_answers: int?,\n  language: string,\n  bloom_level: string\n) -> QuestionGenerationResult {\n  client \"VLLM\"\n  prompt #\"\n    You are an expert military instructor generating questions for your students. Generate exactly 3 questions based on the teaching point provided.\n\n\n    **Teaching Point (English):** {{ teaching_point_en }}\n    **Teaching Point (Arabic):** {{ teaching_point_ar }}\n    {% if context %}**Additional Context:** {{ context }}{% endif %}\n    \n    **Question Type:** {{ question_type }}\n    **Language:** {{ language }} (use \"en\" for English, \"ar\" for Arabic)\n    **Bloom's Taxonomy Level:** {{ bloom_level }}\n    {% if number_of_distractors %}**Number of Distractors:** {{ number_of_distractors }}{% endif %}\n    {% if number_of_correct_answers %}**Number of Correct Answers:** {{ number_of_correct_answers }}{% endif %}\n\n\n    **Bloom's Taxonomy Guidelines:**\n    - REMEMBER: Recall facts, basic concepts, answers\n    - UNDERSTAND: Explain ideas, concepts, summarize\n    - APPLY: Use information in new situations\n    - ANALYZE: Draw connections, examine and break down\n    - EVALUATE: Justify decisions or opinions\n    - CREATE: Produce new or original work\n    \n    **INSTRUCTIONS:**\n    1. Generate exactly 3 questions that test the teaching point at the {{ bloom_level }} level\n    2. Questions should be in {{ language }} language (English if \"en\", Arabic if \"ar\")\n    3. Use the appropriate teaching point (English or Arabic) based on the language\n    \n    **Question Type Specific Rules:**\n    \n    {% if question_type == \"MULTICHOICE\" %}\n    - Create multiple choice questions with {{ number_of_distractors | default(3) }} distractors + 1 correct answer\n    - Use options A, B, C, D (or more if needed)\n    - Answer format: [\"A\"] (single correct answer)\n    - explanation should be null\n    {% elif question_type == \"MULTI_SELECT\" %}\n    - Create multiple select questions with {{ number_of_distractors | default(3) }} distractors + {{ number_of_correct_answers | default(2) }} correct answers\n    - Use options A, B, C, D (or more if needed)\n    - Answer format: [\"A\", \"C\"] (multiple correct answers)\n    - explanation should be null\n    {% elif question_type == \"TRUE_FALSE\" %}\n    - Create true/false questions\n    - Use options: A=\"True\", B=\"False\"\n    - Answer format: [\"A\"] or [\"B\"]\n    - explanation should be null\n    {% elif question_type == \"TRUE_FALSE_JUSTIFICATION\" %}\n    - Create true/false questions with justification\n    - Use options: A=\"True\", B=\"False\"\n    - Answer format: [\"A\"] or [\"B\"]\n    - explanation should contain a detailed explanation/justification\n    {% endif %}\n\n    **Output Requirements:**\n    - Always return exactly 3 questions\n    - Question numbers: 1, 2, 3\n    - Options format: [{\"key\": \"A\", \"value\": \"option text\"}, {\"key\": \"B\", \"value\": \"option text\"}]\n    - Language in response should be \"english\" or \"arabic\" (not \"en\"/\"ar\")\n    - teaching_point should be the English version\n    - Ensure questions are educational, relevant, and appropriately challenging\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n// Test cases for different question types\n\ntest multichoice_english {\n  functions [GenerateQuestions]\n  args {\n    teaching_point_en \"Explain the AFADI LTEM Environment framework element (VUCAR)\"\n    teaching_point_ar \"يشرح عناصر إطار عمل نموذج تدريب وتعليم القيادة في معهد القوات الجوية والدفاع الجوي\"\n    context \"\"\n    question_type \"MULTICHOICE\"\n    number_of_distractors 3\n    number_of_correct_answers null\n    language \"en\"\n    bloom_level \"UNDERSTAND\"\n  }\n}\n\ntest multiselect_english {\n  functions [GenerateQuestions]\n  args {\n    teaching_point_en \"Identify key leadership principles in military operations\"\n    teaching_point_ar \"تحديد المبادئ الرئيسية للقيادة في العمليات العسكرية\"\n    context \"Focus on tactical decision-making scenarios\"\n    question_type \"MULTI_SELECT\"\n    number_of_distractors 2\n    number_of_correct_answers 2\n    language \"en\"\n    bloom_level \"APPLY\"\n  }\n}\n\ntest true_false_arabic {\n  functions [GenerateQuestions]\n  args {\n    teaching_point_en \"Understand communication protocols in air defense\"\n    teaching_point_ar \"فهم بروتوكولات الاتصال في الدفاع الجوي\"\n    context null\n    question_type \"TRUE_FALSE\"\n    number_of_distractors null\n    number_of_correct_answers null\n    language \"ar\"\n    bloom_level \"REMEMBER\"\n  }\n}\n\ntest true_false_justification_english {\n  functions [GenerateQuestions]\n  args {\n    teaching_point_en \"Evaluate the effectiveness of air defense systems\"\n    teaching_point_ar \"تقييم فعالية أنظمة الدفاع الجوي\"\n    context \"Consider both technological and human factors\"\n    question_type \"TRUE_FALSE_JUSTIFICATION\"\n    number_of_distractors null\n    number_of_correct_answers null\n    language \"en\"\n    bloom_level \"EVALUATE\"\n  }\n}\n\ntest arabic_multichoice {\n  functions [GenerateQuestions]\n  args {\n    teaching_point_en \"Analyze tactical advantages of air defense positioning\"\n    teaching_point_ar \"تحليل الميزات التكتيكية لتموضع الدفاع الجوي\"\n    context \"في البيئات الحضرية والصحراوية\"\n    question_type \"MULTICHOICE\"\n    number_of_distractors 3\n    number_of_correct_answers null\n    language \"ar\"\n    bloom_level \"ANALYZE\"\n  }\n}",
    "test.baml": "class WeatherAPI {\n  city string @description(\"the user's city\")\n  timeOfDay string @description(\"As an ISO8601 timestamp\")\n}\n\nfunction UseTool(user_message: string) -> WeatherAPI {\n  client \"openai/gpt-4o\"\n  prompt #\"\n    Extract.... {# we will explain the rest in the guides #}\n  \"#\n}\n",
}

def get_baml_files():
    return _file_map